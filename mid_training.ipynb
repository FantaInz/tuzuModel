{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6601f743-3434-4fb4-8ba0-0c182ebc863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import combine_position_data, log, load_csv, save_csv, calculate_season_average_until_gw\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import xgboost as xgb\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41418993-9c7c-4899-8ae2-9b4a2a712e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Combining position data...\n",
      "INFO: Loaded data from MID_players.csv for season 2022-23.\n",
      "INFO: Loaded data from MID_players.csv for season 2023-24.\n",
      "INFO: Loaded data from MID_players.csv for season 2024-25.\n",
      "INFO: Combined data saved to Fantasy-Premier-League/data/training_data/mid_training_data.csv.\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data\"\n",
    "seasons = [\"2022-23\", \"2023-24\", \"2024-25\"]\n",
    "positions = [\"MID\"]\n",
    "output_file_name = \"mid_training_data.csv\"\n",
    "\n",
    "log(\"Combining position data...\", level=\"INFO\")\n",
    "combine_position_data(data_directory, seasons, positions, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "189abb4c-1fad-48d3-8017-c608384308c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.1208696\ttotal: 871us\tremaining: 173ms\n",
      "50:\tlearn: 3.0369595\ttotal: 36.5ms\tremaining: 107ms\n",
      "100:\tlearn: 3.0275024\ttotal: 73ms\tremaining: 71.5ms\n",
      "150:\tlearn: 3.0167683\ttotal: 109ms\tremaining: 35.4ms\n",
      "199:\tlearn: 3.0090743\ttotal: 143ms\tremaining: 0us\n",
      "RMSE: 3.1624\n",
      "R²: 0.0667\n",
      "Mean Absolute Error (MAE): 2.2327\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tree must be Booster, XGBModel or dict instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Absolute Error (MAE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Feature Importance Plot\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance for Midfielders\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Desktop/tuzuModel/tvenv/lib/python3.12/site-packages/xgboost/plotting.py:96\u001b[0m, in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, values_format, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     importance \u001b[38;5;241m=\u001b[39m booster\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree must be Booster, XGBModel or dict instance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m importance:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooster.get_score() results in empty.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis maybe caused by having all trees as decision dumps.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: tree must be Booster, XGBModel or dict instance"
     ]
    }
   ],
   "source": [
    "training_data_dir = os.path.join(data_directory, \"training_data\")\n",
    "training_file = os.path.join(training_data_dir, output_file_name)\n",
    "mid_data = load_csv(training_file)\n",
    "if mid_data is None:\n",
    "    log(\"Failed to load training data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "# ========================\n",
    "# Feature Engineering\n",
    "# ========================\n",
    "mid_data = mid_data[mid_data[\"minutes\"] > 50]\n",
    "mid_data['was_home'] = mid_data['was_home'].astype(int)\n",
    "mid_data[\"def_atk_diff\"] = mid_data[\"own_defense\"]-mid_data[\"opponent_attack\"]\n",
    "mid_data[\"atk_def_diff\"] = mid_data[\"own_attack\"]-mid_data[\"opponent_defense\"]\n",
    "mid_data = mid_data.sort_values(by=[\"unique_id\", \"season\", \"gameweek\"]).reset_index(drop=True)\n",
    "\n",
    "rolling_periods = [15]\n",
    "base_features = [\"expected_assists\", \"expected_goals\", \"ict_index\", \"team_deep\", \"shots\", \"key_passes\"]\n",
    "\n",
    "for period in rolling_periods:\n",
    "    mid_data[f\"rolling_total_points_{period}\"] = (\n",
    "        mid_data.groupby(\"unique_id\")[\"total_points\"]\n",
    "        .shift(1)\n",
    "        .rolling(window=period, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Usuwamy wszystkie inne cechy i zostawiamy tylko rolling features dla punktów\n",
    "features = [f\"rolling_total_points_{period}\" for period in rolling_periods]\n",
    "target = \"total_points\"\n",
    "\n",
    "# ========================\n",
    "# Train-Test Split\n",
    "# ========================\n",
    "X = mid_data[features]\n",
    "y = mid_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Model\n",
    "model = CatBoostRegressor(\n",
    "    iterations=200,  # Liczba iteracji\n",
    "    learning_rate=0.1,  # Współczynnik uczenia\n",
    "    depth=6,  # Głębokość drzewa\n",
    "    random_seed=42,\n",
    "    verbose=50\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Feature Importance Plot\n",
    "xgb.plot_importance(model, max_num_features=10)\n",
    "plt.title(\"Feature Importance for Midfielders\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "# ========================\n",
    "models_folder = \"models\"\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "model_path = os.path.join(models_folder, \"mid_prediction_model.json\")\n",
    "model.save_model(model_path)\n",
    "log(f\"Model saved at: {model_path}\", level=\"INFO\")\n",
    "\n",
    "# ========================\n",
    "# Optional Hyperparameter Tuning\n",
    "# ========================\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    log(\"Starting hyperparameter tuning...\", level=\"INFO\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(random_stateexpected_goals_conceded=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    log(f\"Best parameters found: {grid_search.best_params_}\", level=\"INFO\")\n",
    "    log(f\"Best RMSE: {-grid_search.best_score_}\", level=\"INFO\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Uncomment to perform tuning\n",
    "# best_model = hyperparameter_tuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4147322-fa4d-4be2-a47b-4e1d4d4e7bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
