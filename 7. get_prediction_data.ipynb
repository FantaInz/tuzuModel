{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b643628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from helpers import log, check_file_exists, load_csv, save_csv, remove_file_or_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9f679b-ff56-4d4f-9fbc-a6e2f6200e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Processed data saved to: Fantasy-Premier-League/data/prediction_files/teams-pred.csv\n"
     ]
    }
   ],
   "source": [
    "# This notebook lets us get csv with the data we want to predict\n",
    "\n",
    "# First let's calculate rolling stats for each team that was active and add their defensive and offensive strengths\n",
    "\n",
    "rolling_windows = [4, 16]\n",
    "stats_to_roll = [\"xG\", \"deep\", \"xGA\", \"deep_allowed\"]\n",
    "team_columns = [\n",
    "    \"id\", \"short_name\", \"strength_attack_home\", \"strength_attack_away\",\n",
    "    \"strength_defence_home\", \"strength_defence_away\"\n",
    "]\n",
    "input_folder = \"Fantasy-Premier-League/data\"\n",
    "output_file = \"Fantasy-Premier-League/data/prediction_files/teams-pred.csv\"\n",
    "output_folder = os.path.dirname(output_file)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "teams_file = os.path.join(input_folder, \"2024-25/teams.csv\")\n",
    "if not check_file_exists(teams_file):\n",
    "    log(f\"Teams file not found: {teams_file}\", level=\"error\")\n",
    "    raise FileNotFoundError(f\"{teams_file} not found.\")\n",
    "\n",
    "teams = load_csv(teams_file)\n",
    "\n",
    "all_team_data = []\n",
    "\n",
    "for team_id in range(1, 21):\n",
    "    team_file = os.path.join(input_folder, f\"teams/team_{team_id}.csv\")\n",
    "    if not check_file_exists(team_file):\n",
    "        log(f\"Team file not found: {team_file}\", level=\"warning\")\n",
    "        continue\n",
    "\n",
    "    team_data = load_csv(team_file)\n",
    "    team_data = team_data.sort_values(by=\"date\")\n",
    "\n",
    "    latest_row = team_data.iloc[[-1]].copy()\n",
    "    rolling_stats = {}\n",
    "    for window in rolling_windows:\n",
    "        for stat in stats_to_roll:\n",
    "            rolling_col = f\"new_{stat}_rolling_{window}\"\n",
    "            rolling_stats[rolling_col] = team_data[stat].rolling(window, min_periods=1).mean().iloc[-1]\n",
    "\n",
    "    for col, value in rolling_stats.items():\n",
    "        latest_row.loc[:, col] = value\n",
    "\n",
    "    team_info = teams[teams[\"id\"] == team_id]\n",
    "    if not team_info.empty:\n",
    "        for col in team_columns:\n",
    "            latest_row.loc[:, col] = team_info.iloc[0][col]\n",
    "\n",
    "    latest_row = latest_row[team_columns + list(rolling_stats.keys())]\n",
    "\n",
    "    all_team_data.append(latest_row)\n",
    "\n",
    "if all_team_data:\n",
    "    merged_data = pd.concat(all_team_data, ignore_index=True)\n",
    "    save_csv(merged_data, output_file)\n",
    "    log(f\"Processed data saved to: {output_file}\")\n",
    "else:\n",
    "    log(\"No team data was processed. Exiting.\", level=\"warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29853abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fixtures with info saved to: Fantasy-Premier-League/data/prediction_files/fixtures-with-info.csv\n"
     ]
    }
   ],
   "source": [
    "# Now let's merge that file with future fixtures to a new one\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/2024-25\"\n",
    "prediction_folder = \"Fantasy-Premier-League/data/prediction_files\"\n",
    "fixtures_file = os.path.join(data_directory, \"fixtures.csv\")\n",
    "teams_file = os.path.join(prediction_folder, \"teams-pred.csv\")\n",
    "output_file = os.path.join(prediction_folder, \"fixtures-with-info.csv\")\n",
    "fixtures = load_csv(fixtures_file)\n",
    "teams_pred = load_csv(teams_file)\n",
    "if fixtures is None or teams_pred is None:\n",
    "    log(\"Required CSV files not found. Exiting.\", level=\"ERROR\")\n",
    "    raise FileNotFoundError(\"Fixtures or teams-pred file not found.\")\n",
    "\n",
    "unfinished_fixtures = fixtures[~fixtures[\"finished\"]]\n",
    "next_8_gameweeks = unfinished_fixtures[\"event\"].dropna().unique()[:8]\n",
    "filtered_fixtures = unfinished_fixtures[unfinished_fixtures[\"event\"].isin(next_8_gameweeks)].copy()\n",
    "\n",
    "for _, team_row in teams_pred.iterrows():\n",
    "    team_id = team_row[\"id\"]\n",
    "    for _, fixture_row in filtered_fixtures.iterrows():\n",
    "        if fixture_row[\"team_h\"] == team_id:\n",
    "            team_column_prefix = \"team_h\"\n",
    "            attack_column = \"strength_attack_home\"\n",
    "            defence_column = \"strength_defence_home\"\n",
    "            short_name_column = \"short_name_h\"\n",
    "        elif fixture_row[\"team_a\"] == team_id:\n",
    "            team_column_prefix = \"team_a\"\n",
    "            attack_column = \"strength_attack_away\"\n",
    "            defence_column = \"strength_defence_away\"\n",
    "            short_name_column = \"short_name_a\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for stat in [\"xG\", \"deep\", \"xGA\", \"deep_allowed\"]:\n",
    "            for window in [4, 16]:\n",
    "                stat_column = f\"new_{stat}_rolling_{window}\"\n",
    "                target_column = f\"{team_column_prefix}_{stat}_rolling_{window}\"\n",
    "                filtered_fixtures.loc[fixture_row.name, target_column] = team_row[stat_column]\n",
    "                \n",
    "        filtered_fixtures.loc[fixture_row.name, attack_column] = team_row[attack_column]\n",
    "        filtered_fixtures.loc[fixture_row.name, defence_column] = team_row[defence_column]\n",
    "        filtered_fixtures.loc[fixture_row.name, short_name_column] = team_row[\"short_name\"]\n",
    "        \n",
    "columns_to_keep = [\n",
    "    \"event\", \"team_h\", \"team_a\", \"short_name_h\", \"short_name_a\", \n",
    "    \"strength_attack_home\", \"strength_defence_home\", \n",
    "    \"strength_attack_away\", \"strength_defence_away\"\n",
    "] + [\n",
    "    f\"team_h_{stat}_rolling_{window}\" for stat in [\"xG\", \"deep\", \"xGA\", \"deep_allowed\"] for window in [4, 16]\n",
    "] + [\n",
    "    f\"team_a_{stat}_rolling_{window}\" for stat in [\"xG\", \"deep\", \"xGA\", \"deep_allowed\"] for window in [4, 16]\n",
    "]\n",
    "\n",
    "final_data = filtered_fixtures[columns_to_keep]\n",
    "\n",
    "# Zapisanie wynikowego pliku\n",
    "os.makedirs(prediction_folder, exist_ok=True)\n",
    "save_csv(final_data, output_file)\n",
    "log(f\"Fixtures with info saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a66105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Saved goalkeepers data to: Fantasy-Premier-League/data/prediction_files/goalkeepers.csv\n",
      "INFO: Saved defenders data to: Fantasy-Premier-League/data/prediction_files/defenders.csv\n",
      "INFO: Saved midfielders data to: Fantasy-Premier-League/data/prediction_files/midfielders.csv\n",
      "INFO: Saved forwards data to: Fantasy-Premier-League/data/prediction_files/forwards.csv\n"
     ]
    }
   ],
   "source": [
    "# Once we have that we can make players_pred.csv where we will add current clubs of the\n",
    "# players and their values, we base on Fantasy-Premier-League/data/master_player_v2.csv and iterate through ones active in\n",
    "# 2024-24\n",
    "# player_raw has element_type (1, 2, 3, 4) which corresponds to positions, in the prediction_files folder we want to have players\n",
    "# for each position\n",
    "data_directory = \"Fantasy-Premier-League/data\"\n",
    "master_players_file = os.path.join(data_directory, \"master_player_v2.csv\")\n",
    "players_raw_file = os.path.join(data_directory, \"2024-25/players_raw.csv\")\n",
    "\n",
    "master_players = load_csv(master_players_file)\n",
    "players_raw = load_csv(players_raw_file)\n",
    "\n",
    "if master_players is None or players_raw is None:\n",
    "    log(\"Failed to load required CSV files. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "    \n",
    "merged_data = pd.merge(\n",
    "    master_players[['24_id', 'Full_Name']],\n",
    "    players_raw[['id', 'now_cost', 'team', 'element_type']],\n",
    "    left_on='24_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ").rename(columns={\n",
    "    'now_cost': 'value',\n",
    "    'team': 'own_team',\n",
    "    'element_type': 'position',\n",
    "    'id': 'Unique_ID'\n",
    "})\n",
    "merged_data = merged_data.drop(columns=['24_id'])\n",
    "\n",
    "position_mapping = {\n",
    "    1: \"goalkeepers\",\n",
    "    2: \"defenders\",\n",
    "    3: \"midfielders\",\n",
    "    4: \"forwards\"\n",
    "}\n",
    "\n",
    "for position, filename in position_mapping.items():\n",
    "    position_data = merged_data[merged_data['position'] == position]\n",
    "    position_output_file = os.path.join(data_directory, \"prediction_files\", f\"{filename}.csv\")\n",
    "    save_csv(position_data, position_output_file)\n",
    "    log(f\"Saved {filename} data to: {position_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f1fa58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Goalkeepers with features saved to: Fantasy-Premier-League/data/prediction_files/goalkeepers_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate must needed things for goalkeepers\n",
    "\n",
    "# We iterate through goalkeepers.csv, based on Unique_ID.toInt we find matching folder in data/consolidated_players. The file ends with\n",
    "# player's unique id\n",
    "# things we need to calculate\n",
    "# selected_features = [\n",
    "#     'bps_rolling_16', 'influence_rolling_4', 'influence_rolling_16', \n",
    "#     'clean_sheets_rolling_4'\n",
    "# ]\n",
    "# we add them to goalkeepers.csv, we do this just for the newest possible data\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "goalkeepers_file = os.path.join(data_directory, \"prediction_files/goalkeepers.csv\")\n",
    "consolidated_players_dir = os.path.join(data_directory, \"consolidated_players\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/goalkeepers_v2.csv\")\n",
    "\n",
    "goalkeepers = load_csv(goalkeepers_file)\n",
    "if goalkeepers is None:\n",
    "    log(\"Failed to load goalkeepers data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "selected_features = {\n",
    "    \"bps\": [16],\n",
    "    \"influence\": [4, 16],\n",
    "    \"clean_sheets\": [4]\n",
    "}\n",
    "\n",
    "for _, row in goalkeepers.iterrows():\n",
    "    unique_id = int(row[\"Unique_ID\"])\n",
    "    \n",
    "    matching_files = [\n",
    "        f for f in os.listdir(consolidated_players_dir) \n",
    "        if f.endswith(f\"_{unique_id}.csv\")\n",
    "    ]\n",
    "    \n",
    "    if not matching_files:\n",
    "        log(f\"No matching file found for Unique_ID {unique_id}. Setting zeros.\", level=\"WARNING\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                goalkeepers.at[row.name, rolling_col] = 0\n",
    "        goalkeepers.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "    \n",
    "    player_file = os.path.join(consolidated_players_dir, matching_files[0])\n",
    "    player_data = load_csv(player_file)\n",
    "    \n",
    "    if player_data is None or \"kickoff_time\" not in player_data.columns:\n",
    "        log(f\"Invalid player data for Unique_ID {unique_id}. Skipping.\", level=\"WARNING\")\n",
    "        continue\n",
    "\n",
    "    player_data[\"date\"] = pd.to_datetime(player_data[\"kickoff_time\"], errors=\"coerce\")\n",
    "    player_data[\"date\"] = player_data[\"date\"].dt.tz_localize(None)\n",
    "    player_data = player_data.sort_values(by=\"date\")\n",
    "\n",
    "    last_4_matches = player_data.tail(4).copy()\n",
    "    last_4_matches[\"filtered_minutes\"] = last_4_matches[\"minutes\"]\n",
    "\n",
    "    zero_indices = last_4_matches[last_4_matches[\"minutes\"] == 0].index\n",
    "    if len(zero_indices) > 0:\n",
    "        first_zero_idx = zero_indices[0]\n",
    "        last_4_matches.at[first_zero_idx, \"filtered_minutes\"] = pd.NA\n",
    "\n",
    "    filtered_minutes = last_4_matches[\"filtered_minutes\"].dropna()\n",
    "    if not filtered_minutes.empty:\n",
    "        xMins = filtered_minutes.mean()\n",
    "    else:\n",
    "        xMins = 0\n",
    "    goalkeepers.at[row.name, \"xMins\"] = xMins\n",
    "\n",
    "    player_data = player_data[player_data[\"minutes\"] >= 60]\n",
    "\n",
    "    if player_data.empty:\n",
    "        log(f\"Player {unique_id} has no matches with >= 60 minutes. Setting zeros.\", level=\"DEBUG\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                goalkeepers.at[row.name, rolling_col] = 0\n",
    "        continue\n",
    "    \n",
    "    latest_row = player_data.iloc[-1]\n",
    "    for stat, windows in selected_features.items():\n",
    "        for window in windows:\n",
    "            rolling_col = f\"{stat}_rolling_{window}\"\n",
    "            if stat in player_data.columns:\n",
    "                latest_value = player_data[stat].rolling(window=window, min_periods=1).mean().iloc[-1]\n",
    "                goalkeepers.at[row.name, rolling_col] = latest_value\n",
    "            else:\n",
    "                log(f\"Stat {stat} not found for Unique_ID {unique_id}. Skipping.\", level=\"WARNING\")\n",
    "\n",
    "save_csv(goalkeepers, output_file)\n",
    "log(f\"Goalkeepers with features saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c533559-991e-4fdc-b7ff-0c427021c548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Goalkeeper predictions saved to: Fantasy-Premier-League/data/prediction_files/gk-ready.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we merge fixtures to goalkeepers\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "fixtures_file = os.path.join(data_directory, \"prediction_files/fixtures-with-info.csv\")\n",
    "goalkeepers_file = os.path.join(data_directory, \"prediction_files/goalkeepers_v2.csv\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/gk-ready.csv\")\n",
    "\n",
    "fixtures = load_csv(fixtures_file)\n",
    "goalkeepers = load_csv(goalkeepers_file)\n",
    "\n",
    "if fixtures is None or goalkeepers is None:\n",
    "    log(\"Failed to load required data files. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "    \n",
    "columns_to_include = [\n",
    "    \"def_atk_diff\", \"opponent_deep_rolling_4\", \"opponent_xG_rolling_16\",\n",
    "    \"own_defense\", \"team_xGA_rolling_16\", \"team_deep_allowed_rolling_16\",\n",
    "    \"was_home\", \"event\", \"short_name_h\", \"short_name_a\", \"opponent_team\"\n",
    "]\n",
    "\n",
    "prediction_data = []\n",
    "\n",
    "for _, fixture in fixtures.iterrows():\n",
    "    for team_column, was_home in [(\"team_h\", True), (\"team_a\", False)]:\n",
    "        team_id = fixture[team_column]\n",
    "        opponent_column = \"team_h\" if team_column == \"team_a\" else \"team_a\"\n",
    "        opponent_id = fixture[opponent_column]\n",
    "        team_gks = goalkeepers[goalkeepers[\"own_team\"] == team_id].copy()\n",
    "        team_gks[\"def_atk_diff\"] = (\n",
    "            fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "            - fixture[f\"strength_attack_{'home' if not was_home else 'away'}\"]\n",
    "        )\n",
    "        team_gks[\"opponent_deep_rolling_4\"] = fixture[f\"{opponent_column}_deep_rolling_4\"]\n",
    "        team_gks[\"opponent_xG_rolling_16\"] = fixture[f\"{opponent_column}_xG_rolling_16\"]\n",
    "        team_gks[\"own_defense\"] = fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "        team_gks[\"team_xGA_rolling_16\"] = fixture[f\"{team_column}_xGA_rolling_16\"]\n",
    "        team_gks[\"team_deep_allowed_rolling_16\"] = fixture[f\"{team_column}_deep_allowed_rolling_16\"]\n",
    "        team_gks[\"was_home\"] = was_home\n",
    "        team_gks[\"event\"] = fixture[\"event\"]\n",
    "        team_gks[\"short_name_h\"] = fixture[\"short_name_h\"]\n",
    "        team_gks[\"short_name_a\"] = fixture[\"short_name_a\"]\n",
    "        team_gks[\"opponent_team\"] = opponent_id\n",
    "        \n",
    "        prediction_data.append(team_gks)\n",
    "\n",
    "if prediction_data:\n",
    "    prediction_df = pd.concat(prediction_data, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    save_csv(prediction_df, output_file)\n",
    "    log(f\"Goalkeeper predictions saved to: {output_file}\")\n",
    "else:\n",
    "    log(\"No prediction data generated. Exiting.\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565c2491-011f-4ac8-b7bf-be2e617525b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No matching file found for Unique_ID 726. Setting xMins to 0.\n",
      "INFO: Defenders with xMins saved to: Fantasy-Premier-League/data/prediction_files/defenders_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate xMins for defenders\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "defenders_file = os.path.join(data_directory, \"prediction_files/defenders.csv\")\n",
    "consolidated_players_dir = os.path.join(data_directory, \"consolidated_players\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/defenders_v2.csv\")\n",
    "\n",
    "defenders = load_csv(defenders_file)\n",
    "if defenders is None:\n",
    "    log(\"Failed to load defenders data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "for _, row in defenders.iterrows():\n",
    "    unique_id = int(row[\"Unique_ID\"])\n",
    "    \n",
    "    matching_files = [\n",
    "        f for f in os.listdir(consolidated_players_dir) \n",
    "        if f.endswith(f\"_{unique_id}.csv\")\n",
    "    ]\n",
    "    \n",
    "    if not matching_files:\n",
    "        log(f\"No matching file found for Unique_ID {unique_id}. Setting xMins to 0.\", level=\"WARNING\")\n",
    "        defenders.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "    \n",
    "    player_file = os.path.join(consolidated_players_dir, matching_files[0])\n",
    "    player_data = load_csv(player_file)\n",
    "    \n",
    "    if player_data is None or \"kickoff_time\" not in player_data.columns:\n",
    "        log(f\"Invalid player data for Unique_ID {unique_id}. Skipping.\", level=\"WARNING\")\n",
    "        defenders.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "\n",
    "    player_data[\"date\"] = pd.to_datetime(player_data[\"kickoff_time\"], errors=\"coerce\")\n",
    "    player_data[\"date\"] = player_data[\"date\"].dt.tz_localize(None)\n",
    "    player_data = player_data.sort_values(by=\"date\")\n",
    "\n",
    "    # Calculate xMins\n",
    "    last_4_matches = player_data.tail(4).copy()\n",
    "    last_4_matches[\"filtered_minutes\"] = last_4_matches[\"minutes\"]\n",
    "\n",
    "    zero_indices = last_4_matches[last_4_matches[\"minutes\"] == 0].index\n",
    "    if len(zero_indices) > 0:\n",
    "        first_zero_idx = zero_indices[0]\n",
    "        last_4_matches.at[first_zero_idx, \"filtered_minutes\"] = pd.NA\n",
    "\n",
    "    filtered_minutes = last_4_matches[\"filtered_minutes\"].dropna()\n",
    "    if not filtered_minutes.empty:\n",
    "        xMins = filtered_minutes.mean()\n",
    "    else:\n",
    "        xMins = 0\n",
    "    defenders.at[row.name, \"xMins\"] = xMins\n",
    "\n",
    "save_csv(defenders, output_file)\n",
    "log(f\"Defenders with xMins saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60d1536-6514-45c0-a849-b6f8bb14e9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Defender predictions saved to: Fantasy-Premier-League/data/prediction_files/def-ready.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we merge fixtures to defenders\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "fixtures_file = os.path.join(data_directory, \"prediction_files/fixtures-with-info.csv\")\n",
    "defenders_file = os.path.join(data_directory, \"prediction_files/defenders_v2.csv\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/def-ready.csv\")\n",
    "\n",
    "fixtures = load_csv(fixtures_file)\n",
    "defenders = load_csv(defenders_file)\n",
    "\n",
    "if fixtures is None or defenders is None:\n",
    "    log(\"Failed to load required data files. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "columns_to_include = [\n",
    "    \"atk_def_diff\", \"def_atk_diff\", \"opponent_xG_rolling_4\", \"opponent_deep_rolling_4\",\n",
    "    \"opponent_xGA_rolling_4\", \"opponent_deep_allowed_rolling_4\", \"team_xG_rolling_4\", \n",
    "    \"team_xGA_rolling_4\", \"opponent_xGA_rolling_16\", \"opponent_deep_allowed_rolling_16\", \n",
    "    \"opponent_xG_rolling_16\", \"opponent_deep_rolling_16\", \"opponent_defense\", \"own_defense\", \n",
    "    \"team_xG_rolling_16\", \"team_deep_rolling_16\", \"team_xGA_rolling_16\", \"team_deep_allowed_rolling_16\", \n",
    "    \"was_home\", \"event\", \"short_name_h\", \"short_name_a\", \"opponent_team\"\n",
    "]\n",
    "\n",
    "prediction_data = []\n",
    "\n",
    "for _, fixture in fixtures.iterrows():\n",
    "    for team_column, was_home in [(\"team_h\", True), (\"team_a\", False)]:\n",
    "        team_id = fixture[team_column]\n",
    "        opponent_column = \"team_h\" if team_column == \"team_a\" else \"team_a\"\n",
    "        opponent_id = fixture[opponent_column]\n",
    "        team_defs = defenders[defenders[\"own_team\"] == team_id].copy()\n",
    "        \n",
    "        # Calculating features\n",
    "        team_defs[\"atk_def_diff\"] = (\n",
    "            fixture[f\"strength_attack_{'home' if was_home else 'away'}\"]\n",
    "            - fixture[f\"strength_defence_{'home' if not was_home else 'away'}\"]\n",
    "        )\n",
    "        team_defs[\"def_atk_diff\"] = (\n",
    "            fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "            - fixture[f\"strength_attack_{'home' if not was_home else 'away'}\"]\n",
    "        )\n",
    "        team_defs[\"opponent_xG_rolling_4\"] = fixture[f\"{opponent_column}_xG_rolling_4\"]\n",
    "        team_defs[\"opponent_deep_rolling_4\"] = fixture[f\"{opponent_column}_deep_rolling_4\"]\n",
    "        team_defs[\"opponent_xGA_rolling_4\"] = fixture[f\"{opponent_column}_xGA_rolling_4\"]\n",
    "        team_defs[\"opponent_deep_allowed_rolling_4\"] = fixture[f\"{opponent_column}_deep_allowed_rolling_4\"]\n",
    "        team_defs[\"team_xG_rolling_4\"] = fixture[f\"{team_column}_xG_rolling_4\"]\n",
    "        team_defs[\"team_xGA_rolling_4\"] = fixture[f\"{team_column}_xGA_rolling_4\"]\n",
    "        team_defs[\"opponent_xGA_rolling_16\"] = fixture[f\"{opponent_column}_xGA_rolling_16\"]\n",
    "        team_defs[\"opponent_deep_allowed_rolling_16\"] = fixture[f\"{opponent_column}_deep_allowed_rolling_16\"]\n",
    "        team_defs[\"opponent_xG_rolling_16\"] = fixture[f\"{opponent_column}_xG_rolling_16\"]\n",
    "        team_defs[\"opponent_deep_rolling_16\"] = fixture[f\"{opponent_column}_deep_rolling_16\"]\n",
    "        team_defs[\"opponent_defense\"] = fixture[f\"strength_defence_{'home' if not was_home else 'away'}\"]\n",
    "        team_defs[\"own_defense\"] = fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "        team_defs[\"team_xG_rolling_16\"] = fixture[f\"{team_column}_xG_rolling_16\"]\n",
    "        team_defs[\"team_deep_rolling_16\"] = fixture[f\"{team_column}_deep_rolling_16\"]\n",
    "        team_defs[\"team_xGA_rolling_16\"] = fixture[f\"{team_column}_xGA_rolling_16\"]\n",
    "        team_defs[\"team_deep_allowed_rolling_16\"] = fixture[f\"{team_column}_deep_allowed_rolling_16\"]\n",
    "        team_defs[\"was_home\"] = was_home\n",
    "        team_defs[\"event\"] = fixture[\"event\"]\n",
    "        team_defs[\"short_name_h\"] = fixture[\"short_name_h\"]\n",
    "        team_defs[\"short_name_a\"] = fixture[\"short_name_a\"]\n",
    "        team_defs[\"opponent_team\"] = opponent_id\n",
    "        \n",
    "        prediction_data.append(team_defs)\n",
    "\n",
    "if prediction_data:\n",
    "    prediction_df = pd.concat(prediction_data, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    save_csv(prediction_df, output_file)\n",
    "    log(f\"Defender predictions saved to: {output_file}\")\n",
    "else:\n",
    "    log(\"No prediction data generated. Exiting.\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03404d0c-dfcc-476b-8e5d-c3524de7fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No matching file found for Unique_ID 725. Setting zeros.\n",
      "INFO: Midfielders with features saved to: Fantasy-Premier-League/data/prediction_files/midfielders_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate must needed things for midfielders\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "midfielders_file = os.path.join(data_directory, \"prediction_files/midfielders.csv\")\n",
    "consolidated_players_dir = os.path.join(data_directory, \"consolidated_players\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/midfielders_v2.csv\")\n",
    "\n",
    "midfielders = load_csv(midfielders_file)\n",
    "if midfielders is None:\n",
    "    log(\"Failed to load midfielders data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "selected_features = {\n",
    "    \"shots\": [4, 16],\n",
    "    \"key_passes\": [16],\n",
    "    \"expected_goals\": [4, 16],\n",
    "    \"expected_assists\": [4],\n",
    "    \"goals_scored\": [4, 16],\n",
    "    \"ict_index\": [4, 16],\n",
    "    \"influence\": [16],\n",
    "    \"creativity\": [16],\n",
    "    \"threat\": [4, 16],\n",
    "    \"assists\": [4, 16],\n",
    "    \"total_points\": [4, 16]\n",
    "}\n",
    "\n",
    "for _, row in midfielders.iterrows():\n",
    "    unique_id = int(row[\"Unique_ID\"])\n",
    "    \n",
    "    matching_files = [\n",
    "        f for f in os.listdir(consolidated_players_dir) \n",
    "        if f.endswith(f\"_{unique_id}.csv\")\n",
    "    ]\n",
    "    \n",
    "    if not matching_files:\n",
    "        log(f\"No matching file found for Unique_ID {unique_id}. Setting zeros.\", level=\"WARNING\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                midfielders.at[row.name, rolling_col] = 0\n",
    "        midfielders.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "    \n",
    "    player_file = os.path.join(consolidated_players_dir, matching_files[0])\n",
    "    player_data = load_csv(player_file)\n",
    "    \n",
    "    if player_data is None or \"kickoff_time\" not in player_data.columns:\n",
    "        log(f\"Invalid player data for Unique_ID {unique_id}. Setting zeros.\", level=\"WARNING\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                midfielders.at[row.name, rolling_col] = 0\n",
    "        midfielders.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "\n",
    "    player_data[\"date\"] = pd.to_datetime(player_data[\"kickoff_time\"], errors=\"coerce\")\n",
    "    player_data[\"date\"] = player_data[\"date\"].dt.tz_localize(None)\n",
    "    player_data = player_data.sort_values(by=\"date\")\n",
    "\n",
    "    # Calculate xMins\n",
    "    last_4_matches = player_data.tail(4).copy()\n",
    "    last_4_matches[\"filtered_minutes\"] = last_4_matches[\"minutes\"]\n",
    "\n",
    "    zero_indices = last_4_matches[last_4_matches[\"minutes\"] == 0].index\n",
    "    if len(zero_indices) > 0:\n",
    "        first_zero_idx = zero_indices[0]\n",
    "        last_4_matches.at[first_zero_idx, \"filtered_minutes\"] = pd.NA\n",
    "\n",
    "    filtered_minutes = last_4_matches[\"filtered_minutes\"].dropna()\n",
    "    if not filtered_minutes.empty:\n",
    "        xMins = filtered_minutes.mean()\n",
    "    else:\n",
    "        xMins = 0\n",
    "    midfielders.at[row.name, \"xMins\"] = xMins\n",
    "\n",
    "    # Filter rows with at least 60 minutes\n",
    "    player_data = player_data[player_data[\"minutes\"] >= 60]\n",
    "\n",
    "    if player_data.empty:\n",
    "        log(f\"Player {unique_id} has no matches with >= 60 minutes. Setting zeros.\", level=\"DEBUG\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                midfielders.at[row.name, rolling_col] = 0\n",
    "        continue\n",
    "\n",
    "    # Calculate rolling stats\n",
    "    for stat, windows in selected_features.items():\n",
    "        for window in windows:\n",
    "            rolling_col = f\"{stat}_rolling_{window}\"\n",
    "            if stat in player_data.columns:\n",
    "                latest_value = player_data[stat].rolling(window=window, min_periods=1).mean().iloc[-1]\n",
    "                midfielders.at[row.name, rolling_col] = latest_value\n",
    "            else:\n",
    "                log(f\"Stat {stat} not found for Unique_ID {unique_id}. Setting zero for {rolling_col}.\", level=\"WARNING\")\n",
    "                midfielders.at[row.name, rolling_col] = 0\n",
    "\n",
    "save_csv(midfielders, output_file)\n",
    "log(f\"Midfielders with features saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020c0fab-133c-46e6-9fcc-9829de958d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Midfielder predictions saved to: Fantasy-Premier-League/data/prediction_files/mid-ready.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we merge fixtures to midfielders\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "fixtures_file = os.path.join(data_directory, \"prediction_files/fixtures-with-info.csv\")\n",
    "midfielders_file = os.path.join(data_directory, \"prediction_files/midfielders_v2.csv\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/mid-ready.csv\")\n",
    "\n",
    "fixtures = load_csv(fixtures_file)\n",
    "midfielders = load_csv(midfielders_file)\n",
    "\n",
    "if fixtures is None or midfielders is None:\n",
    "    log(\"Failed to load required data files. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "columns_to_include = [\n",
    "    \"atk_def_diff\", \"def_atk_diff\", \"opponent_xGA_rolling_4\", \"team_xG_rolling_4\", \n",
    "    \"team_deep_rolling_4\", \"opponent_xGA_rolling_16\", \"opponent_deep_allowed_rolling_16\", \n",
    "    \"own_attack\", \"opponent_defense\", \"own_defense\", \"team_xG_rolling_16\", \"team_deep_rolling_16\", \n",
    "    \"was_home\", \"event\", \"short_name_h\", \"short_name_a\", \"opponent_team\"\n",
    "]\n",
    "\n",
    "prediction_data = []\n",
    "\n",
    "for _, fixture in fixtures.iterrows():\n",
    "    for team_column, was_home in [(\"team_h\", True), (\"team_a\", False)]:\n",
    "        team_id = fixture[team_column]\n",
    "        opponent_column = \"team_h\" if team_column == \"team_a\" else \"team_a\"\n",
    "        opponent_id = fixture[opponent_column]\n",
    "        team_mids = midfielders[midfielders[\"own_team\"] == team_id].copy()\n",
    "        \n",
    "        # Calculating features\n",
    "        team_mids[\"atk_def_diff\"] = (\n",
    "            fixture[f\"strength_attack_{'home' if was_home else 'away'}\"]\n",
    "            - fixture[f\"strength_defence_{'home' if not was_home else 'away'}\"]\n",
    "        )\n",
    "        team_mids[\"def_atk_diff\"] = (\n",
    "            fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "            - fixture[f\"strength_attack_{'home' if not was_home else 'away'}\"]\n",
    "        )\n",
    "        team_mids[\"opponent_xGA_rolling_4\"] = fixture[f\"{opponent_column}_xGA_rolling_4\"]\n",
    "        team_mids[\"team_xG_rolling_4\"] = fixture[f\"{team_column}_xG_rolling_4\"]\n",
    "        team_mids[\"team_deep_rolling_4\"] = fixture[f\"{team_column}_deep_rolling_4\"]\n",
    "        team_mids[\"opponent_xGA_rolling_16\"] = fixture[f\"{opponent_column}_xGA_rolling_16\"]\n",
    "        team_mids[\"opponent_deep_allowed_rolling_16\"] = fixture[f\"{opponent_column}_deep_allowed_rolling_16\"]\n",
    "        team_mids[\"own_attack\"] = fixture[f\"strength_attack_{'home' if was_home else 'away'}\"]\n",
    "        team_mids[\"opponent_defense\"] = fixture[f\"strength_defence_{'home' if not was_home else 'away'}\"]\n",
    "        team_mids[\"own_defense\"] = fixture[f\"strength_defence_{'home' if was_home else 'away'}\"]\n",
    "        team_mids[\"team_xG_rolling_16\"] = fixture[f\"{team_column}_xG_rolling_16\"]\n",
    "        team_mids[\"team_deep_rolling_16\"] = fixture[f\"{team_column}_deep_rolling_16\"]\n",
    "        team_mids[\"was_home\"] = was_home\n",
    "        team_mids[\"event\"] = fixture[\"event\"]\n",
    "        team_mids[\"short_name_h\"] = fixture[\"short_name_h\"]\n",
    "        team_mids[\"short_name_a\"] = fixture[\"short_name_a\"]\n",
    "        team_mids[\"opponent_team\"] = opponent_id\n",
    "        \n",
    "        prediction_data.append(team_mids)\n",
    "\n",
    "if prediction_data:\n",
    "    prediction_df = pd.concat(prediction_data, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    save_csv(prediction_df, output_file)\n",
    "    log(f\"Midfielder predictions saved to: {output_file}\")\n",
    "else:\n",
    "    log(\"No prediction data generated. Exiting.\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00b7245e-a761-4f7f-8771-890193c43803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Forwards with features saved to: Fantasy-Premier-League/data/prediction_files/forwards_v2.csv\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "forwards_file = os.path.join(data_directory, \"prediction_files/forwards.csv\")\n",
    "consolidated_players_dir = os.path.join(data_directory, \"consolidated_players\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/forwards_v2.csv\")\n",
    "\n",
    "forwards = load_csv(forwards_file)\n",
    "if forwards is None:\n",
    "    log(\"Failed to load forwards data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "selected_features = {\n",
    "    \"shots\": [4],\n",
    "    \"expected_goals\": [4],\n",
    "    \"expected_assists\": [16],\n",
    "    \"goals_scored\": [4, 16],\n",
    "    \"bps\": [16],\n",
    "    \"ict_index\": [4, 16],\n",
    "    \"influence\": [4],\n",
    "    \"threat\": [16],\n",
    "    \"assists\": [4, 16],\n",
    "    \"total_points\": [16]\n",
    "}\n",
    "\n",
    "for _, row in forwards.iterrows():\n",
    "    unique_id = int(row[\"Unique_ID\"])\n",
    "    \n",
    "    matching_files = [\n",
    "        f for f in os.listdir(consolidated_players_dir) \n",
    "        if f.endswith(f\"_{unique_id}.csv\")\n",
    "    ]\n",
    "    \n",
    "    if not matching_files:\n",
    "        log(f\"No matching file found for Unique_ID {unique_id}. Setting zeros.\", level=\"WARNING\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                forwards.at[row.name, rolling_col] = 0\n",
    "        forwards.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "    \n",
    "    player_file = os.path.join(consolidated_players_dir, matching_files[0])\n",
    "    player_data = load_csv(player_file)\n",
    "    \n",
    "    if player_data is None or \"kickoff_time\" not in player_data.columns:\n",
    "        log(f\"Invalid player data for Unique_ID {unique_id}. Setting zeros.\", level=\"WARNING\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                forwards.at[row.name, rolling_col] = 0\n",
    "        forwards.at[row.name, \"xMins\"] = 0\n",
    "        continue\n",
    "\n",
    "    player_data[\"date\"] = pd.to_datetime(player_data[\"kickoff_time\"], errors=\"coerce\")\n",
    "    player_data[\"date\"] = player_data[\"date\"].dt.tz_localize(None)\n",
    "    player_data = player_data.sort_values(by=\"date\")\n",
    "\n",
    "    # Calculate xMins\n",
    "    last_4_matches = player_data.tail(4).copy()\n",
    "    last_4_matches[\"filtered_minutes\"] = last_4_matches[\"minutes\"]\n",
    "\n",
    "    zero_indices = last_4_matches[last_4_matches[\"minutes\"] == 0].index\n",
    "    if len(zero_indices) > 0:\n",
    "        first_zero_idx = zero_indices[0]\n",
    "        last_4_matches.at[first_zero_idx, \"filtered_minutes\"] = pd.NA\n",
    "\n",
    "    filtered_minutes = last_4_matches[\"filtered_minutes\"].dropna()\n",
    "    if not filtered_minutes.empty:\n",
    "        xMins = filtered_minutes.mean()\n",
    "    else:\n",
    "        xMins = 0\n",
    "    forwards.at[row.name, \"xMins\"] = xMins\n",
    "\n",
    "    # Filter rows with at least 60 minutes\n",
    "    player_data = player_data[player_data[\"minutes\"] >= 60]\n",
    "\n",
    "    if player_data.empty:\n",
    "        log(f\"Player {unique_id} has no matches with >= 60 minutes. Setting zeros.\", level=\"DEBUG\")\n",
    "        for stat, windows in selected_features.items():\n",
    "            for window in windows:\n",
    "                rolling_col = f\"{stat}_rolling_{window}\"\n",
    "                forwards.at[row.name, rolling_col] = 0\n",
    "        continue\n",
    "\n",
    "    # Calculate rolling stats\n",
    "    for stat, windows in selected_features.items():\n",
    "        for window in windows:\n",
    "            rolling_col = f\"{stat}_rolling_{window}\"\n",
    "            if stat in player_data.columns:\n",
    "                latest_value = player_data[stat].rolling(window=window, min_periods=1).mean().iloc[-1]\n",
    "                forwards.at[row.name, rolling_col] = latest_value\n",
    "            else:\n",
    "                log(f\"Stat {stat} not found for Unique_ID {unique_id}. Setting zero for {rolling_col}.\", level=\"DEBUG\")\n",
    "                forwards.at[row.name, rolling_col] = 0\n",
    "\n",
    "save_csv(forwards, output_file)\n",
    "log(f\"Forwards with features saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9f07fea-8131-45f0-a471-4e416463f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Forward predictions saved to: Fantasy-Premier-League/data/prediction_files/fwd-ready.csv\n"
     ]
    }
   ],
   "source": [
    "# Now we merge fixtures to forwards\n",
    "\n",
    "data_directory = \"Fantasy-Premier-League/data/\"\n",
    "fixtures_file = os.path.join(data_directory, \"prediction_files/fixtures-with-info.csv\")\n",
    "forwards_file = os.path.join(data_directory, \"prediction_files/forwards_v2.csv\")\n",
    "output_file = os.path.join(data_directory, \"prediction_files/fwd-ready.csv\")\n",
    "\n",
    "fixtures = load_csv(fixtures_file)\n",
    "forwards = load_csv(forwards_file)\n",
    "\n",
    "if fixtures is None or forwards is None:\n",
    "    log(\"Failed to load required data files. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "columns_to_include = [\n",
    "    \"own_attack\", \"opponent_defense\", \"opponent_xGA_rolling_4\", \n",
    "    \"opponent_deep_allowed_rolling_4\", \"opponent_deep_allowed_rolling_16\", \n",
    "    \"team_xG_rolling_4\", \"team_xG_rolling_16\", \n",
    "    \"was_home\", \"event\", \"short_name_h\", \"short_name_a\", \"opponent_team\"\n",
    "]\n",
    "\n",
    "prediction_data = []\n",
    "\n",
    "for _, fixture in fixtures.iterrows():\n",
    "    for team_column, was_home in [(\"team_h\", True), (\"team_a\", False)]:\n",
    "        team_id = fixture[team_column]\n",
    "        opponent_column = \"team_h\" if team_column == \"team_a\" else \"team_a\"\n",
    "        opponent_id = fixture[opponent_column]\n",
    "        team_fwds = forwards[forwards[\"own_team\"] == team_id].copy()\n",
    "        \n",
    "        # Calculating features\n",
    "        team_fwds[\"own_attack\"] = fixture[f\"strength_attack_{'home' if was_home else 'away'}\"]\n",
    "        team_fwds[\"opponent_defense\"] = fixture[f\"strength_defence_{'home' if not was_home else 'away'}\"]\n",
    "        team_fwds[\"opponent_xGA_rolling_4\"] = fixture[f\"{opponent_column}_xGA_rolling_4\"]\n",
    "        team_fwds[\"opponent_deep_allowed_rolling_4\"] = fixture[f\"{opponent_column}_deep_allowed_rolling_4\"]\n",
    "        team_fwds[\"opponent_deep_allowed_rolling_16\"] = fixture[f\"{opponent_column}_deep_allowed_rolling_16\"]\n",
    "        team_fwds[\"team_xG_rolling_4\"] = fixture[f\"{team_column}_xG_rolling_4\"]\n",
    "        team_fwds[\"team_xG_rolling_16\"] = fixture[f\"{team_column}_xG_rolling_16\"]\n",
    "        team_fwds[\"was_home\"] = was_home\n",
    "        team_fwds[\"event\"] = fixture[\"event\"]\n",
    "        team_fwds[\"short_name_h\"] = fixture[\"short_name_h\"]\n",
    "        team_fwds[\"short_name_a\"] = fixture[\"short_name_a\"]\n",
    "        team_fwds[\"opponent_team\"] = opponent_id\n",
    "        \n",
    "        prediction_data.append(team_fwds)\n",
    "\n",
    "if prediction_data:\n",
    "    prediction_df = pd.concat(prediction_data, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    save_csv(prediction_df, output_file)\n",
    "    log(f\"Forward predictions saved to: {output_file}\")\n",
    "else:\n",
    "    log(\"No prediction data generated. Exiting.\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0990c-43a3-44c2-b70a-e4a147875283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
