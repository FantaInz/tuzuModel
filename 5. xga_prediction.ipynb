{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c989f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from helpers import load_csv, save_csv, log, check_file_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46097f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_data(data_directory, positions):\n",
    "    \"\"\"Load and merge data for specified positions.\"\"\"\n",
    "    merged_data = pd.DataFrame()\n",
    "    for position in positions:\n",
    "        position_file = os.path.join(data_directory, \"processed_data\", position, f\"{position}_final.csv\")\n",
    "        if check_file_exists(position_file):\n",
    "            position_data = load_csv(position_file)\n",
    "            if position_data is not None:\n",
    "                merged_data = pd.concat([merged_data, position_data], ignore_index=True)\n",
    "                log(f\"Merged {position_file}\")\n",
    "        else:\n",
    "            log(f\"File {position_file} not found. Skipping.\", level=\"WARNING\")\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fef8aa-ad1b-4cc0-adda-16df19414f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_blended_conversion_rate(data, k=5):\n",
    "    \"\"\"\n",
    "    Calculate blended conversion rate using cumulative goals and xG as a proxy for player efficiency.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The input data containing 'id', 'cumulative_goals', and 'cumulative_xg'.\n",
    "        k (float): Smoothing factor for blending.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'id' and 'blended_conversion_rate'.\n",
    "    \"\"\"\n",
    "    # Group by player (id) and calculate cumulative metrics\n",
    "    grouped = data.groupby(\"id\").agg(\n",
    "        total_goals=(\"cumulative_goals\", \"max\"),\n",
    "        total_xg=(\"cumulative_xg\", \"max\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate player-level conversion rate\n",
    "    grouped[\"player_conversion_rate\"] = grouped[\"total_goals\"] / grouped[\"total_xg\"]\n",
    "    grouped[\"player_conversion_rate\"] = grouped[\"player_conversion_rate\"].fillna(0)  # Handle division by zero\n",
    "\n",
    "    # Calculate league-wide conversion rate\n",
    "    total_goals = grouped[\"total_goals\"].sum()\n",
    "    total_xg = grouped[\"total_xg\"].sum()\n",
    "    league_conversion_rate = total_goals / total_xg if total_xg > 0 else 1\n",
    "\n",
    "    # Blend conversion rate using xG as weight\n",
    "    grouped[\"weight\"] = grouped[\"total_xg\"] / (grouped[\"total_xg\"] + k)\n",
    "    grouped[\"blended_conversion_rate\"] = (\n",
    "        grouped[\"weight\"] * grouped[\"player_conversion_rate\"] +\n",
    "        (1 - grouped[\"weight\"]) * league_conversion_rate\n",
    "    )\n",
    "\n",
    "    return grouped[[\"id\", \"blended_conversion_rate\"]]\n",
    "\n",
    "def add_blended_conversion_rate(data):\n",
    "    \"\"\"\n",
    "    Add blended conversion rate to the dataset based on cumulative metrics.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The input dataset containing player stats.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataset with the blended conversion rate added.\n",
    "    \"\"\"\n",
    "    # Calculate blended conversion rate\n",
    "    blended_rate_df = calculate_blended_conversion_rate(data)\n",
    "\n",
    "    # Merge blended rate back into the original dataset\n",
    "    data = data.merge(blended_rate_df, on=\"id\", how=\"left\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76c151f-0c87-4243-9d0c-774be5ecd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_points_for_goals(data, prediction_column, output_column):\n",
    "    \"\"\"\n",
    "    Multiply predicted goals by points based on player position.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Dataset containing 'POS' and predicted goals.\n",
    "        prediction_column (str): Column with predicted goals (e.g., 'predicted_xG').\n",
    "        output_column (str): Column to store calculated points.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataset with calculated points.\n",
    "    \"\"\"\n",
    "    # Define points for each position\n",
    "    position_points = {2: 6, 3: 5, 4: 4}  # 2 -> Defender, 3 -> Midfielder, 4 -> Forward\n",
    "\n",
    "    # Map points to positions and calculate final points\n",
    "    data[output_column] = data[\"POS\"].map(position_points) * data[prediction_column]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c27217a-dcc0-4750-a878-a697626e0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"Perform data preprocessing and feature engineering.\"\"\"\n",
    "    # Rename \"id\" to \"unique_id\" for consistency\n",
    "    data.rename(columns={\"id\": \"unique_id\"}, inplace=True)\n",
    "\n",
    "    # Feature engineering\n",
    "    data['was_home'] = data['was_home'].astype(int)\n",
    "    data['home_crowd_effect'] = data['was_home'] * data['crowds']\n",
    "    data[\"_unique_id_copy\"] = data[\"unique_id\"]\n",
    "    data[\"_pos_copy\"] = data[\"POS\"]\n",
    "\n",
    "    # Sort for rolling and cumulative calculations\n",
    "    data = data.sort_values(by=[\"unique_id\", \"season\", \"gameweek\"])\n",
    "\n",
    "    # One-hot encoding for categorical columns\n",
    "    dummy_columns = [\"POS\", \"home_crowd_effect\", \"unique_id\", \"own_team\", \"opponent_team\"]\n",
    "    data = pd.get_dummies(data, columns=dummy_columns)\n",
    "\n",
    "    data[\"unique_id\"] = data[\"_unique_id_copy\"]\n",
    "    data[\"POS\"] = data[\"_pos_copy\"]\n",
    "    data.drop(columns=[\"_unique_id_copy\"], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8107fcd2-eeb8-4941-821d-4132645e19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data, model_path, prediction_column):\n",
    "    \"\"\"Load model, generate predictions, and add to data.\"\"\"\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model(model_path)\n",
    "    print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "    # Ensure only trained features are used\n",
    "    trained_feature_names = model.get_booster().feature_names\n",
    "    prediction_data = data.reindex(columns=trained_feature_names, fill_value=0)\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = model.predict(prediction_data)\n",
    "    predictions = np.clip(predictions, a_min=0, a_max=None)  # Clamp negative predictions to 0\n",
    "    data[prediction_column] = predictions\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647e8ca1-8fa7-48b4-a340-02f4626ee6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(data, output_columns, prediction_column, output_file):\n",
    "    \"\"\"Format and save predictions to a CSV file.\"\"\"\n",
    "    output_data = data[output_columns + [prediction_column]]\n",
    "    output_data.loc[:, \"gameweek\"] = output_data[\"gameweek\"].astype(int)  # Ensure gameweek is an integer\n",
    "    output_data = output_data.pivot(index=[\"unique_id\", \"first_name\", \"second_name\"], columns=\"gameweek\", values=prediction_column)\n",
    "    output_data.reset_index(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    output_data.columns = [\n",
    "        f\"gw_{col}_{prediction_column}\" if isinstance(col, int) else col for col in output_data.columns\n",
    "    ]\n",
    "\n",
    "    # Sort by gameweek columns\n",
    "    gameweek_columns = sorted(\n",
    "        [col for col in output_data.columns if col.startswith(\"gw_\")],\n",
    "        key=lambda x: int(x.split('_')[1])  # Extract the gameweek number for proper sorting\n",
    "    )\n",
    "    output_data = output_data.sort_values(by=gameweek_columns, ascending=False)\n",
    "\n",
    "    # Save to file\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    output_data.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb1e4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Merged Fantasy-Premier-League/data/2024-25/processed_data/DEF/DEF_final.csv\n",
      "INFO: Merged Fantasy-Premier-League/data/2024-25/processed_data/MID/MID_final.csv\n",
      "INFO: Merged Fantasy-Premier-League/data/2024-25/processed_data/FWD/FWD_final.csv\n",
      "Loaded model from models/xgboost_xg_prediction_model.json\n",
      "Predictions saved to predictions/xG_predictions.csv\n",
      "Predictions saved to predictions/goal_predictions.csv\n",
      "Predictions saved to predictions/goal_points.csv\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data/2024-25\"\n",
    "positions = [\"DEF\", \"MID\", \"FWD\"]\n",
    "model_path = \"models/xgboost_xg_prediction_model.json\"\n",
    "output_file_xg = \"predictions/xG_predictions.csv\"\n",
    "output_file_goals = \"predictions/goal_predictions.csv\"\n",
    "output_file_goalpoints = \"predictions/goal_points.csv\"\n",
    "prediction_column = \"predicted_xG\"\n",
    "\n",
    "# Load and merge data\n",
    "merged_data = load_and_merge_data(data_directory, positions)\n",
    "\n",
    "# Add blended conversion rate to the dataset\n",
    "merged_data = add_blended_conversion_rate(merged_data)\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessed_data = preprocess_data(merged_data)\n",
    "\n",
    "# Make predictions\n",
    "predicted_data = make_predictions(preprocessed_data, model_path, prediction_column)\n",
    "\n",
    "predicted_data[\"predicted_goals\"] = (\n",
    "    predicted_data[prediction_column] * predicted_data[\"blended_conversion_rate\"]\n",
    ")\n",
    "\n",
    "predicted_data = calculate_points_for_goals(\n",
    "    predicted_data, \n",
    "    prediction_column=\"predicted_goals\", \n",
    "    output_column=\"predicted_points\"\n",
    ")\n",
    "\n",
    "# Save xG predictions\n",
    "save_predictions(predicted_data, [\"unique_id\", \"first_name\", \"second_name\", \"gameweek\"], \"predicted_xG\", output_file_xg)\n",
    "\n",
    "save_predictions(predicted_data, [\"unique_id\", \"first_name\", \"second_name\", \"gameweek\"], \"predicted_goals\", output_file_goals)\n",
    "\n",
    "save_predictions(\n",
    "    predicted_data, \n",
    "    [\"unique_id\", \"first_name\", \"second_name\", \"gameweek\"], \n",
    "    \"predicted_points\", \n",
    "    output_file_goalpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fe649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvenv",
   "language": "python",
   "name": "tvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
