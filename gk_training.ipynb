{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2524d1-ded2-4cd0-8cb0-9af33e780d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import combine_position_data, log, load_csv, save_csv, calculate_season_average_until_gw\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619016f8-d7c6-4832-a098-c28b0e1aab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Combining position data...\n",
      "INFO: Loaded data from GK_players.csv for season 2022-23.\n",
      "INFO: Loaded data from GK_players.csv for season 2023-24.\n",
      "INFO: Loaded data from GK_players.csv for season 2024-25.\n",
      "INFO: Combined data saved to Fantasy-Premier-League/data/training_data/gk_training_data.csv.\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data\"\n",
    "seasons = [\"2022-23\", \"2023-24\", \"2024-25\"]\n",
    "positions = [\"GK\"]\n",
    "output_file_name = \"gk_training_data.csv\"\n",
    "\n",
    "log(\"Combining position data...\", level=\"INFO\")\n",
    "combine_position_data(data_directory, seasons, positions, output_file_name, filter_zeros=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d383355-409e-48ea-affa-e567453e1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "  RMSE: 2.5611, R²: 0.1401, MAE: 2.0133\n",
      "Test Metrics:\n",
      "  RMSE: 2.5611, R²: 0.0108, MAE: 2.2563\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tree must be Booster, XGBModel or dict instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Feature Importance Plot\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance for Goalkeepers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Desktop/tuzuModel/tvenv/lib/python3.12/site-packages/xgboost/plotting.py:96\u001b[0m, in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, values_format, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     importance \u001b[38;5;241m=\u001b[39m booster\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree must be Booster, XGBModel or dict instance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m importance:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooster.get_score() results in empty.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis maybe caused by having all trees as decision dumps.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: tree must be Booster, XGBModel or dict instance"
     ]
    }
   ],
   "source": [
    "training_data_dir = os.path.join(data_directory, \"training_data\")\n",
    "training_file = os.path.join(training_data_dir, output_file_name)\n",
    "gk_data = load_csv(training_file)\n",
    "if gk_data is None:\n",
    "    log(\"Failed to load training data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "# ========================\n",
    "# Feature Engineering\n",
    "# ========================\n",
    "gk_data = gk_data[gk_data[\"minutes\"] > 60]\n",
    "gk_data['was_home'] = gk_data['was_home'].astype(int)\n",
    "gk_data[\"def_atk_diff\"] = gk_data[\"own_defense\"]-gk_data[\"opponent_attack\"]\n",
    "\n",
    "rolling_periods = [3]\n",
    "base_features = [\"saves\", \"opponent_xg\"]\n",
    "gk_data = gk_data.sort_values(by=[\"unique_id\", \"season\", \"gameweek\"]).reset_index(drop=True)\n",
    "\n",
    "for period in rolling_periods:\n",
    "    for feature in base_features:\n",
    "        if feature == \"opponent_xg\" or feature ==\"opponent_deep\":\n",
    "            gk_data[f\"rolling_{feature}_{period}\"] = (\n",
    "                gk_data.groupby(\"unique_id\")[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=period, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "        else:\n",
    "            gk_data[f\"rolling_{feature}_{period}\"] = (\n",
    "                gk_data[gk_data[\"minutes\"] > 0]\n",
    "                .groupby(\"unique_id\")[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=period, min_periods=1)\n",
    "                .mean()\n",
    "                .reindex(gk_data.index, fill_value=0)\n",
    "            )\n",
    "\n",
    "\n",
    "dummy_columns = [\"was_home\", \"unique_id\"]\n",
    "gk_data = pd.get_dummies(gk_data, columns=dummy_columns)\n",
    "# Final Feature Set\n",
    "rolling_features = [f\"rolling_{feature}_{period}\" for feature in base_features for period in rolling_periods]\n",
    "additional_features = [\"def_atk_diff\", \"value\"]\n",
    "numerical_features = rolling_features + additional_features\n",
    "categorical_features = [\n",
    "    col for col in gk_data.columns if any(col.startswith(f\"{dummy_col}_\") for dummy_col in dummy_columns)\n",
    "]\n",
    "features = numerical_features + categorical_features\n",
    "target = \"total_points\"\n",
    "\n",
    "# ========================\n",
    "# Train-Test Split\n",
    "# ========================\n",
    "X = gk_data[features]\n",
    "y = gk_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train XGBoost Model\n",
    "model = rf_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate on training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "rmse_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_test = root_mean_squared_error(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Metrics:\")\n",
    "print(f\"  RMSE: {rmse_train:.4f}, R²: {r2_train:.4f}, MAE: {mae_train:.4f}\")\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"  RMSE: {rmse_test:.4f}, R²: {r2_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "\n",
    "# Feature Importance Plot\n",
    "xgb.plot_importance(model, max_num_features=10)\n",
    "plt.title(\"Feature Importance for Goalkeepers\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "# ========================\n",
    "models_folder = \"models\"\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "model_path = os.path.join(models_folder, \"gk_prediction_model.json\")\n",
    "model.save_model(model_path)\n",
    "log(f\"Model saved at: {model_path}\", level=\"INFO\")\n",
    "\n",
    "# ========================\n",
    "# Optional Hyperparameter Tuning\n",
    "# ========================\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    log(\"Starting hyperparameter tuning...\", level=\"INFO\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(random_stateexpected_goals_conceded=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    log(f\"Best parameters found: {grid_search.best_params_}\", level=\"INFO\")\n",
    "    log(f\"Best RMSE: {-grid_search.best_score_}\", level=\"INFO\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Uncomment to perform tuning\n",
    "# best_model = hyperparameter_tuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75afeeb-7906-4633-9e72-e769ee0b953a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c359f-3e05-43ad-a001-facf24bb16c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
