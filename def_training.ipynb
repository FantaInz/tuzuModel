{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaeb74f-fe2b-4520-96b6-68a50eafac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import combine_position_data, log, load_csv, save_csv, calculate_season_average_until_gw\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7146c91-0025-40cd-8b09-08b3a23cb3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Combining position data...\n",
      "INFO: Loaded data from DEF_players.csv for season 2022-23.\n",
      "INFO: Loaded data from DEF_players.csv for season 2023-24.\n",
      "INFO: Loaded data from DEF_players.csv for season 2024-25.\n",
      "INFO: Combined data saved to Fantasy-Premier-League/data/training_data/def_training_data.csv.\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data\"\n",
    "seasons = [\"2022-23\", \"2023-24\", \"2024-25\"]\n",
    "positions = [\"DEF\"]\n",
    "output_file_name = \"def_training_data.csv\"\n",
    "\n",
    "log(\"Combining position data...\", level=\"INFO\")\n",
    "combine_position_data(data_directory, seasons, positions, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8e523-0cb2-4ac4-80e3-5259617f29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yosyzm/Desktop/tuzuModel/helpers.py:88: DtypeWarning: Columns (58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "training_data_dir = os.path.join(data_directory, \"training_data\")\n",
    "training_file = os.path.join(training_data_dir, output_file_name)\n",
    "def_data = load_csv(training_file)\n",
    "if def_data is None:\n",
    "    log(\"Failed to load training data. Exiting.\", level=\"ERROR\")\n",
    "    exit()\n",
    "\n",
    "# ========================\n",
    "# Feature Engineering\n",
    "# ========================\n",
    "def_data['was_home'] = def_data['was_home'].astype(int)\n",
    "def_data[\"def_atk_diff\"] = def_data[\"own_defense\"]-def_data[\"opponent_attack\"]\n",
    "def_data[\"atk_def_diff\"] = def_data[\"own_attack\"]-def_data[\"opponent_defense\"]\n",
    "def_data = def_data.sort_values(by=[\"unique_id\", \"season\", \"gameweek\"]).reset_index(drop=True)\n",
    "\n",
    "rolling_periods = [3, 5, 8, 12]\n",
    "base_features = [\"opponent_xg\", \"expected_assists\", \"expected_goals\", \"ict_index\", \"opponent_deep\", \"bps\"]\n",
    "\n",
    "for period in rolling_periods:\n",
    "    for feature in base_features:\n",
    "        if feature == \"opponent_xg\" or feature ==\"opponent_deep\" or feature ==\"team_deep\":\n",
    "            def_data[f\"rolling_{feature}_{period}\"] = (\n",
    "                def_data.groupby(\"unique_id\")[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=period, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "        else:\n",
    "            def_data[f\"rolling_{feature}_{period}\"] = (\n",
    "                def_data[def_data[\"minutes\"] > 0]\n",
    "                .groupby(\"unique_id\")[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=period, min_periods=1)\n",
    "                .mean()\n",
    "                .reindex(def_data.index, fill_value=0)\n",
    "            )\n",
    "\n",
    "def_data[\"avg_yellow_cards\"] = (\n",
    "    def_data[def_data[\"minutes\"] > 0]\n",
    "    .groupby(\"unique_id\")[\"yellow_cards\"]\n",
    "    .shift(1)\n",
    "    .expanding()\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "dummy_columns = [\"was_home\", \"unique_id\"]\n",
    "def_data = pd.get_dummies(def_data, columns=dummy_columns)\n",
    "# Final Feature Set\n",
    "rolling_features = [f\"rolling_{feature}_{period}\" for feature in base_features for period in rolling_periods]\n",
    "additional_features = [\"def_atk_diff\", \"value\", \"atk_def_diff\", \"avg_yellow_cards\"]\n",
    "numerical_features = rolling_features + additional_features\n",
    "categorical_features = [\n",
    "    col for col in def_data.columns if any(col.startswith(f\"{dummy_col}_\") for dummy_col in dummy_columns)\n",
    "]\n",
    "features = numerical_features + categorical_features\n",
    "target = \"total_points\"\n",
    "\n",
    "# ========================\n",
    "# Train-Test Split\n",
    "# ========================\n",
    "X = def_data[features]\n",
    "y = def_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"RÂ²: {r2:.4f}\")\n",
    "\n",
    "# Feature Importance Plot\n",
    "xgb.plot_importance(model, max_num_features=10)\n",
    "plt.title(\"Feature Importance for Defenders\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "# ========================\n",
    "models_folder = \"models\"\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "model_path = os.path.join(models_folder, \"def_prediction_model.json\")\n",
    "model.save_model(model_path)\n",
    "log(f\"Model saved at: {model_path}\", level=\"INFO\")\n",
    "\n",
    "# ========================\n",
    "# Optional Hyperparameter Tuning\n",
    "# ========================\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    log(\"Starting hyperparameter tuning...\", level=\"INFO\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(random_stateexpected_goals_conceded=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    log(f\"Best parameters found: {grid_search.best_params_}\", level=\"INFO\")\n",
    "    log(f\"Best RMSE: {-grid_search.best_score_}\", level=\"INFO\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Uncomment to perform tuning\n",
    "# best_model = hyperparameter_tuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194cea7a-0a13-43cd-a718-97ffea74692b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
