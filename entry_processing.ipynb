{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fd57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from rapidfuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a887bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get each player position and id for the season\n",
    "def process_season_data(data_directory, seasons):\n",
    "    for season in seasons:\n",
    "        season_path = os.path.join(data_directory, season)\n",
    "\n",
    "        if os.path.isdir(season_path):\n",
    "            player_idlist_path = os.path.join(season_path, \"player_idlist.csv\")\n",
    "            cleaned_players_path = os.path.join(season_path, \"cleaned_players.csv\")\n",
    "            output_file_path = os.path.join(season_path, \"processed_players.csv\")\n",
    "\n",
    "            if os.path.exists(player_idlist_path) and os.path.exists(cleaned_players_path):\n",
    "                try:\n",
    "                    player_idlist_df = pd.read_csv(player_idlist_path)\n",
    "                    cleaned_players_df = pd.read_csv(cleaned_players_path)\n",
    "\n",
    "                    merged_df = pd.merge(\n",
    "                        player_idlist_df[['id', 'first_name', 'second_name']],\n",
    "                        cleaned_players_df[['first_name', 'second_name', 'element_type']],\n",
    "                        on=['first_name', 'second_name'],\n",
    "                        how='inner'\n",
    "                    )\n",
    "\n",
    "                    # Rename element_type to position\n",
    "                    merged_df.rename(columns={'element_type': 'position'}, inplace=True)\n",
    "\n",
    "                    # Save the DataFrame to a new file\n",
    "                    merged_df.to_csv(output_file_path, index=False)\n",
    "                    print(f\"Processed and saved: {output_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing season {season}: {e}\")\n",
    "            else:\n",
    "                print(f\"Missing required files in {season_path}: player_idlist.csv or cleaned_players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c25904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Fantasy-Premier-League/data/2024-25/processed_players.csv\n",
      "Processed and saved: Fantasy-Premier-League/data/2023-24/processed_players.csv\n",
      "Processed and saved: Fantasy-Premier-League/data/2022-23/processed_players.csv\n",
      "Processed and saved: Fantasy-Premier-League/data/2021-22/processed_players.csv\n",
      "Processed and saved: Fantasy-Premier-League/data/2020-21/processed_players.csv\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"Fantasy-Premier-League/data\"\n",
    "seasons = [\"2024-25\", \"2023-24\", \"2022-23\", \"2021-22\", \"2020-21\"]\n",
    "process_season_data(data_directory, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea403c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_player_ids(data_directory, seasons, output_file=\"master_player_list.csv\"):\n",
    "    player_data = {}\n",
    "    next_unique_id = 1\n",
    "    \n",
    "    # We want to base ids on 2024-25 season\n",
    "    main_season = \"2024-25\"\n",
    "    main_season_path = os.path.join(data_directory, main_season, \"processed_players.csv\")\n",
    "    \n",
    "    if os.path.exists(main_season_path):\n",
    "        try:\n",
    "            main_processed_df = pd.read_csv(main_season_path)\n",
    "            \n",
    "            for _, row in main_processed_df.iterrows():\n",
    "                full_name = f\"{row['first_name']} {row['second_name']}\"\n",
    "                if full_name not in player_data:\n",
    "                    player_data[full_name] = {\n",
    "                        \"First_Name\": row['first_name'],\n",
    "                        \"Last_Name\": row['second_name'],\n",
    "                        \"Unique_ID\": row['id']\n",
    "                    }\n",
    "                # Add the 24_id for the main season\n",
    "                player_data[full_name]['24_id'] = row['id']\n",
    "                next_unique_id = max(next_unique_id, row['id'] + 1)  # Ensure greater ids to avoid reusing\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {main_season_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Missing processed_players.csv for season: {main_season}\")\n",
    "\n",
    "    # Process other seasons\n",
    "    for season in seasons:\n",
    "        \n",
    "        if season != main_season:\n",
    "            season_path = os.path.join(data_directory, season, \"processed_players.csv\")\n",
    "            if os.path.exists(season_path):\n",
    "                try:\n",
    "                    processed_df = pd.read_csv(season_path)\n",
    "                    \n",
    "                    season_short = season[:4][-2:]\n",
    "                    \n",
    "                    for _, row in processed_df.iterrows():\n",
    "                        full_name = f\"{row['first_name']} {row['second_name']}\"\n",
    "                        if full_name not in player_data:\n",
    "                            player_data[full_name] = {\n",
    "                                \"First_Name\": row['first_name'],\n",
    "                                \"Last_Name\": row['second_name'],\n",
    "                                \"Unique_ID\": next_unique_id\n",
    "                            }\n",
    "                            next_unique_id += 1\n",
    "                        # Add the season ID\n",
    "                        player_data[full_name][f\"{season_short}_id\"] = row['id']\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {season_path}: {e}\")\n",
    "\n",
    "    consolidated_df = pd.DataFrame.from_dict(player_data, orient='index').reset_index(drop=True)\n",
    "    \n",
    "    # Ensure all ID columns are integers\n",
    "    id_columns = [col for col in consolidated_df.columns if col.endswith(\"_id\")]\n",
    "    consolidated_df[id_columns] = consolidated_df[id_columns].fillna(-1).astype(int)\n",
    "    \n",
    "    # Save the consolidated DataFrame to a CSV\n",
    "    output_path = os.path.join(data_directory, output_file)\n",
    "    consolidated_df.to_csv(output_path, index=False)\n",
    "    print(f\"Consolidated player data saved to {output_path}\")\n",
    "\n",
    "    return consolidated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994fc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated player data saved to Fantasy-Premier-League/data/master_player_list.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>24_id</th>\n",
       "      <th>23_id</th>\n",
       "      <th>22_id</th>\n",
       "      <th>21_id</th>\n",
       "      <th>20_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fábio</td>\n",
       "      <td>Ferreira Vieira</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gabriel</td>\n",
       "      <td>Fernando de Jesus</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>263</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gabriel</td>\n",
       "      <td>dos Santos Magalhães</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kai</td>\n",
       "      <td>Havertz</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karl</td>\n",
       "      <td>Hein</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>646</td>\n",
       "      <td>655</td>\n",
       "      <td>532</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Theo</td>\n",
       "      <td>Corbeanu</td>\n",
       "      <td>1749</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>Perry</td>\n",
       "      <td>1750</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>Lewis</td>\n",
       "      <td>Richards</td>\n",
       "      <td>1751</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Nigel</td>\n",
       "      <td>Lonwijk</td>\n",
       "      <td>1752</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>Willian José</td>\n",
       "      <td>Da Silva</td>\n",
       "      <td>1753</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1753 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        First_Name             Last_Name  Unique_ID  24_id  23_id  22_id  \\\n",
       "0            Fábio       Ferreira Vieira          1      1      4     25   \n",
       "1          Gabriel     Fernando de Jesus          2      2      8     28   \n",
       "2          Gabriel  dos Santos Magalhães          3      3      5     16   \n",
       "3              Kai               Havertz          4      4      6    145   \n",
       "4             Karl                  Hein          5      5    646    655   \n",
       "...            ...                   ...        ...    ...    ...    ...   \n",
       "1748          Theo              Corbeanu       1749     -1     -1     -1   \n",
       "1749        Taylor                 Perry       1750     -1     -1     -1   \n",
       "1750         Lewis              Richards       1751     -1     -1     -1   \n",
       "1751         Nigel               Lonwijk       1752     -1     -1     -1   \n",
       "1752  Willian José              Da Silva       1753     -1     -1     -1   \n",
       "\n",
       "      21_id  20_id  \n",
       "0        -1     -1  \n",
       "1       263    282  \n",
       "2        -1     -1  \n",
       "3       141    500  \n",
       "4       532     -1  \n",
       "...     ...    ...  \n",
       "1748     -1    610  \n",
       "1749     -1    611  \n",
       "1750     -1    615  \n",
       "1751     -1    629  \n",
       "1752     -1    642  \n",
       "\n",
       "[1753 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_player_ids(data_directory, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa790f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script below was used to get duplicate candidates\n",
    "\n",
    "# consolidated_file = \"master_player_list.csv\"\n",
    "# consolidated_path = os.path.join(data_directory, consolidated_file)\n",
    "# consolidated_df = pd.read_csv(consolidated_path)\n",
    "\n",
    "# SIMILARITY_THRESHOLD = 80\n",
    "# FIRST_NAME_SIMILARITY_THRESHOLD = 40\n",
    "\n",
    "# def is_pair(player_a, player_b, id_columns):\n",
    "#     # Check for ID overlaps across seasons\n",
    "#     id_overlap = any(\n",
    "#         player_a[col] != -1 and player_b[col] != -1\n",
    "#         for col in id_columns\n",
    "#     )\n",
    "#     if id_overlap:\n",
    "#         return False\n",
    "    \n",
    "#     # Now we check the names similarity\n",
    "#     first_name_similarity = fuzz.partial_ratio(player_a[\"First_Name\"], player_b[\"First_Name\"])\n",
    "#     if first_name_similarity <= FIRST_NAME_SIMILARITY_THRESHOLD:\n",
    "#         return False\n",
    "    \n",
    "#     # Check if one last name is contained in the other\n",
    "#     if player_a[\"Last_Name\"] in player_b[\"Last_Name\"] or player_b[\"Last_Name\"] in player_a[\"Last_Name\"]:\n",
    "#         return True\n",
    "\n",
    "#     # Calculate string similarity only if containment check fails\n",
    "#     similarity = fuzz.partial_ratio(player_a[\"Last_Name\"], player_b[\"Last_Name\"])\n",
    "#     return similarity >= SIMILARITY_THRESHOLD\n",
    "\n",
    "# # Identify all ID columns\n",
    "# id_columns = [col for col in consolidated_df.columns if col.endswith(\"_id\")]\n",
    "# pairs = []\n",
    "# for i, player_a in consolidated_df.iterrows():\n",
    "#     for j, player_b in consolidated_df.iterrows():\n",
    "#         if i >= j:  # Avoid duplicate and self-pairs\n",
    "#             continue\n",
    "#         if is_pair(player_a, player_b, id_columns):\n",
    "#             pairs.append({\n",
    "#                 \"Player_A_First_Name\": player_a[\"First_Name\"],\n",
    "#                 \"Player_A_Last_Name\": player_a[\"Last_Name\"],\n",
    "#                 \"Player_A_Unique_ID\": player_a[\"Unique_ID\"],\n",
    "#                 \"Player_B_First_Name\": player_b[\"First_Name\"],\n",
    "#                 \"Player_B_Last_Name\": player_b[\"Last_Name\"],\n",
    "#                 \"Player_B_Unique_ID\": player_b[\"Unique_ID\"],\n",
    "#             })\n",
    "\n",
    "# # Convert pairs to a DataFrame\n",
    "# created_csv_dir = \"created_csv\"\n",
    "# pairs_df = pd.DataFrame(pairs)\n",
    "# if not pairs_df.empty:\n",
    "#     output_path = os.path.join(created_csv_dir, \"players_with_potential_renames.csv\")\n",
    "#     pairs_df.to_csv(output_path, index=False)\n",
    "#     print(f\"Potential renamed players saved to {output_path}\")\n",
    "# else:\n",
    "#     print(\"No potential renamed players found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a78425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing ID in master_player_list. Larger ID: 1093, Smaller ID: 729\n",
      "Warning: Missing ID in master_player_list. Larger ID: 1400, Smaller ID: 918\n",
      "Warning: Missing ID in master_player_list. Larger ID: 1313, Smaller ID: 1075\n",
      "Warning: Missing ID in master_player_list. Larger ID: 1745, Smaller ID: 1550\n"
     ]
    }
   ],
   "source": [
    "# After manual checking the candidates now we have to update master_player_list.csv \n",
    "# (new file will me master_player_verified)\n",
    "verified_renames = pd.read_csv(\"created_csv/verified_renames.csv\")\n",
    "master_player_file = \"master_player_list.csv\"\n",
    "master_player_path = os.path.join(data_directory, master_player_file)\n",
    "master_player_list = pd.read_csv(master_player_path)\n",
    "\n",
    "for _, row in verified_renames.iterrows():\n",
    "    id_a = row[\"Player_A_Unique_ID\"]\n",
    "    id_b = row[\"Player_B_Unique_ID\"]\n",
    "\n",
    "    larger_id, smaller_id = (id_b, id_a) if id_b > id_a else (id_a, id_b)\n",
    "\n",
    "    # Find the rows for the larger and smaller IDs in master_player_list\n",
    "    larger_row = master_player_list[master_player_list[\"Unique_ID\"] == larger_id]\n",
    "    smaller_row = master_player_list[master_player_list[\"Unique_ID\"] == smaller_id]\n",
    "\n",
    "    # Ensure both rows exist before proceeding\n",
    "    if larger_row.empty or smaller_row.empty:\n",
    "        print(f\"Warning: Missing ID in master_player_list. Larger ID: {larger_id}, Smaller ID: {smaller_id}\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # Update the smaller ID row with non-negative season data from the larger ID row\n",
    "    for season in [\"24_id\", \"23_id\", \"22_id\", \"21_id\", \"20_id\"]:\n",
    "        if larger_row[season].iloc[0] != -1:\n",
    "            master_player_list.loc[master_player_list[\"Unique_ID\"] == smaller_id, season] = larger_row[season].iloc[0]\n",
    "\n",
    "    # Remove the larger ID player\n",
    "    master_player_list = master_player_list[master_player_list[\"Unique_ID\"] != larger_id]\n",
    "\n",
    "# Save the updated master player list to a new file\n",
    "master_player_list.to_csv(\"Fantasy-Premier-League/data/master_player_verified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0574d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_processed_players_and_rename_folders(data_directory, seasons, master_player_file):\n",
    "    master_player_path = os.path.join(data_directory, master_player_file)\n",
    "    master_player_verified = pd.read_csv(master_player_path)\n",
    "\n",
    "    for season in seasons:\n",
    "        if season == \"2024-25\":\n",
    "            print(f\"Skipping season: {season}\")\n",
    "            continue\n",
    "\n",
    "        season_path = os.path.join(data_directory, season)\n",
    "        players_folder_path = os.path.join(season_path, \"players\")\n",
    "        processed_file = os.path.join(season_path, \"processed_players.csv\")\n",
    "        verified_file = os.path.join(season_path, \"processed_players_verified.csv\")\n",
    "\n",
    "        season_short = season[:4][-2:]  # Extract season short (e.g., \"21\", \"22\")\n",
    "        season_id_column = f\"{season_short}_id\"\n",
    "\n",
    "        if os.path.exists(processed_file):\n",
    "            print(f\"Processing season: {season}\")\n",
    "            processed_players = pd.read_csv(processed_file)\n",
    "\n",
    "            # Get all player folders in the players folder\n",
    "            player_folders = []\n",
    "            if os.path.exists(players_folder_path):\n",
    "                player_folders = [\n",
    "                    f for f in os.listdir(players_folder_path)\n",
    "                    if os.path.isdir(os.path.join(players_folder_path, f))\n",
    "                ]\n",
    "\n",
    "            # Update IDs and rename folders\n",
    "            for index, row in processed_players.iterrows():\n",
    "                current_id = row[\"id\"]\n",
    "                # Match the season-specific ID in master_player_verified\n",
    "                matching_row = master_player_verified[master_player_verified[season_id_column] == current_id]\n",
    "\n",
    "                if not matching_row.empty:\n",
    "                    new_data = matching_row.iloc[0]\n",
    "                    new_unique_id = new_data[\"Unique_ID\"]\n",
    "                    new_first_name = new_data[\"First_Name\"]\n",
    "                    new_last_name = new_data[\"Last_Name\"]\n",
    "\n",
    "                    # Update the processed_players row\n",
    "                    processed_players.at[index, \"id\"] = new_unique_id\n",
    "                    processed_players.at[index, \"first_name\"] = new_first_name\n",
    "                    processed_players.at[index, \"second_name\"] = new_last_name\n",
    "\n",
    "                    # Find and rename the player's folder\n",
    "                    matching_folder = next(\n",
    "                        (f for f in player_folders if f.endswith(f\"_{current_id}\")), None\n",
    "                    )\n",
    "                    if matching_folder:\n",
    "                        old_path = os.path.join(players_folder_path, matching_folder)\n",
    "                        new_folder_name = f\"{new_first_name}_{new_last_name}_{new_unique_id}\"\n",
    "                        new_path = os.path.join(players_folder_path, new_folder_name)\n",
    "\n",
    "                        # Ensure destination directory does not already exist\n",
    "                        if os.path.exists(new_path):\n",
    "                            continue\n",
    "                        try:\n",
    "                            shutil.move(old_path, new_path)\n",
    "                            print(f\"Successfully renamed folder {matching_folder} to {new_folder_name}\")\n",
    "                            player_folders.remove(matching_folder)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error moving {old_path} to {new_path}: {e}\")\n",
    "\n",
    "            # Save the updated processed_players file\n",
    "            processed_players.to_csv(verified_file, index=False)\n",
    "            print(f\"Updated file and folders saved for season: {season}\")\n",
    "        else:\n",
    "            print(f\"Processed players file not found for season: {season}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a54bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping season: 2024-25\n",
      "Processing season: 2023-24\n",
      "Saving updated processed_players...\n",
      "    id first_name           second_name position\n",
      "0  675    Folarin               Balogun      FWD\n",
      "1  676     Cédric          Alves Soares      DEF\n",
      "2  677    Mohamed                Elneny      MID\n",
      "3    1      Fábio       Ferreira Vieira      MID\n",
      "4    3    Gabriel  dos Santos Magalhães      DEF\n",
      "Updated file and folders saved for season: 2023-24\n",
      "Processing season: 2022-23\n",
      "Saving updated processed_players...\n",
      "    id first_name second_name position\n",
      "0  682     Granit       Xhaka      MID\n",
      "1  677    Mohamed      Elneny      MID\n",
      "2  202        Rob     Holding      DEF\n",
      "3   20     Thomas      Partey      MID\n",
      "4   13     Martin    Ødegaard      MID\n",
      "Updated file and folders saved for season: 2022-23\n",
      "Processing season: 2021-22\n",
      "Saving updated processed_players...\n",
      "    id      first_name      second_name position\n",
      "0  248           Bernd             Leno       GK\n",
      "1  680      Rúnar Alex        Rúnarsson       GK\n",
      "2  848         Willian  Borges da Silva      MID\n",
      "3  791  Pierre-Emerick       Aubameyang      FWD\n",
      "4  676          Cédric     Alves Soares      DEF\n",
      "Updated file and folders saved for season: 2021-22\n",
      "Processing season: 2020-21\n",
      "Saving updated processed_players...\n",
      "     id      first_name           second_name position\n",
      "0  1552           Mesut                  Özil      MID\n",
      "1  1553        Sokratis      Papastathopoulos      DEF\n",
      "2  1554           David  Luiz Moreira Marinho      DEF\n",
      "3   791  Pierre-Emerick            Aubameyang      MID\n",
      "4   676          Cédric          Alves Soares      DEF\n",
      "Updated file and folders saved for season: 2020-21\n"
     ]
    }
   ],
   "source": [
    "master_player_file = \"master_player_verified.csv\"\n",
    "\n",
    "update_processed_players_and_rename_folders(data_directory, seasons, master_player_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4047bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvenv",
   "language": "python",
   "name": "tvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
